{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from scipy.io import arff\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6f412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = pd.read_csv('./UniversityDataset1/test.csv') ## add .csv filename of complete data \n",
    "permit = act[act['class'] == \"p\"]\n",
    "df1 = pd.DataFrame(permit)\n",
    "df = df1.drop(columns = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c73086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import ngrams\n",
    "from scipy import cluster\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.special import comb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import adjusted_rand_score, homogeneity_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import scipy.spatial.distance as ssd\n",
    "\n",
    "class nTreeClus:\n",
    "    def __init__(self, sequences, n, method, ntree=10, C= None, verbose=1):\n",
    "        \"\"\" nTreeClus is a clustering method by Hadi Jahanshahi and Mustafa Gokce Baydogan.\n",
    "        The method is suitable for clustering categorical time series (sequences). \n",
    "        You can always have access to the examples and description in \n",
    "        https://github.com/HadiJahanshahi/nTreeClus\n",
    "        If you have any question about the code, you may email hadijahanshahi [a t] gmail . com\n",
    "        \n",
    "        prerequisites:\n",
    "            numpy\n",
    "            pandas\n",
    "            sklearn\n",
    "            scipy\n",
    "        \n",
    "        Args:\n",
    "            sequences: a list of sequences to be clustered\n",
    "            n: \"the window length\" or \"n\" in nTreeclus. You may provide it or it will be\n",
    "                calculated automatically if no input has been suggested.\n",
    "                Currently, the default value of \"the square root of average sequences' lengths\" is taken.\n",
    "            method: \n",
    "                DT:          Decision Tree\n",
    "                DT_position: Decision Tree enhanced by position index\n",
    "                RF:          Random Forest\n",
    "                RF_position: Random Forest enhanced by position index\n",
    "                All:         all four methods\n",
    "            ntree: number of trees to be used in RF method. The default value is 10. \n",
    "                (Setting a small value decreases accuracy, and a large value may increase the complexity. \n",
    "                 no less than 5 and no greater than 20 is recommended.)\n",
    "            C: number of clusters. If it is not provided, it will be calculated using silhouette_score.\n",
    "            verbose [binary]: It indicates whether to print the outputs or not. \n",
    "\n",
    "        Returns:\n",
    "            'C_DT': \"the optimal number of clusters for Decision Tree\",\n",
    "            'C_RF': \"the optimal number of clusters for Random Forest\",\n",
    "            'Parameter n': the parameter of the nTreeClus (n) - either calculated or manually entered\n",
    "            'distance_DT': \"sparse distance between sequences for Decision Tree\",\n",
    "            'distance_RF': \"sparse distance between sequences for Random Forest\",\n",
    "            'labels_DT': \"labels based on the optimal number of clusters for DT\",\n",
    "            'labels_RF': \"labels based on the optimal number of clusters for RF\".\n",
    "                \n",
    "                NOTE: in order to convert the distance output to a square distance matrix, \n",
    "                    \"scipy.spatial.distance.squareform\" should be used.\n",
    "                    \n",
    "        ## simple example with the output\n",
    "        sequences = ['evidence','evident','provide','unconventional','convene']\n",
    "        model     = nTreeClus(sequences, n = None, ntree=5, method = \"All\")\n",
    "        model.nTreeClus()\n",
    "        model.output()\n",
    "        # {'C_DT': 2,\n",
    "        # 'distance_DT': array([0.05508882, 0.43305329, 0.68551455, 0.43305329, 0.5       ,\n",
    "        #        0.7226499 , 0.5       , 0.86132495, 0.75      , 0.4452998 ]),\n",
    "        # 'labels_DT': array([0, 0, 0, 1, 1]),\n",
    "        # 'C_RF': 2,\n",
    "        # 'distance_RF': array([0.10557281, 0.5527864 , 0.58960866, 0.64222912, 0.55      ,\n",
    "        #       0.72470112, 0.7       , 0.83940899, 0.95      , 0.26586965]),\n",
    "        # 'labels_RF': array([0, 0, 0, 1, 1]),\n",
    "        # 'Parameter n': 4}\n",
    "        \"\"\"\n",
    "        self.n                                 = n   # Parameter n\n",
    "        self.method                            = method\n",
    "        self.ntree                             = ntree\n",
    "        self.C_DT                              = C\n",
    "        self.C_RF                              = C\n",
    "        self.C_DT_p                            = C\n",
    "        self.C_RF_p                            = C\n",
    "        self.sequences                         = sequences\n",
    "        self.seg_mat                           = None\n",
    "        self.Dist_tree_terminal_cosine         = None # distance_DT\n",
    "        self.assignment_tree_terminal_cosine   = None # labels_DT\n",
    "        self.Dist_tree_terminal_cosine_p       = None # distance_DT + position\n",
    "        self.assignment_tree_terminal_cosine_p = None # labels_DT   + position\n",
    "        self.Dist_RF_terminal_cosine           = None # distance_RF\n",
    "        self.assignment_RF_terminal_cosine     = None # labels_RF\n",
    "        self.Dist_RF_terminal_cosine_p         = None # distance_RF + position\n",
    "        self.assignment_RF_terminal_cosine_p   = None # labels_RF   + position\n",
    "        self.verbose                           = verbose\n",
    "        self.running_timeSegmentation          = None\n",
    "        self.running_timeDT                    = None\n",
    "        self.running_timeDT_p                  = None\n",
    "        self.running_timeRF                    = None\n",
    "        self.running_timeRF_p                  = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def purity_score(clusters, classes):\n",
    "        \"\"\"\n",
    "        Calculate the purity score for the given cluster assignments and ground truth classes\n",
    "        \n",
    "        :param clusters: the cluster assignments array\n",
    "        :type clusters: numpy.array\n",
    "        \n",
    "        :param classes: the ground truth classes\n",
    "        :type classes: numpy.array\n",
    "        \n",
    "        :returns: the purity score\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        clusters = np.array(clusters)\n",
    "        classes = np.array(classes)\n",
    "        A = np.c_[(clusters,classes)]\n",
    "\n",
    "        n_accurate = 0.\n",
    "\n",
    "        for j in np.unique(A[:,0]):\n",
    "            z = A[A[:,0] == j, 1]\n",
    "            x = np.argmax(np.bincount(z))\n",
    "            n_accurate += len(z[z == x])\n",
    "\n",
    "        return n_accurate / A.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rand_index_score(clusters, classes):\n",
    "        clusters = np.array(clusters)\n",
    "        classes = np.array(classes)\n",
    "        tp_plus_fp = comb(np.bincount(clusters), 2).sum()\n",
    "        tp_plus_fn = comb(np.bincount(classes), 2).sum()\n",
    "        A = np.c_[(clusters, classes)]\n",
    "        tp = sum(comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum()\n",
    "                for i in set(clusters))\n",
    "        fp = tp_plus_fp - tp\n",
    "        fn = tp_plus_fn - tp\n",
    "        tn = comb(len(A), 2) - tp - fp - fn\n",
    "        return (tp + tn) / (tp + fp + fn + tn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _1nn(Ground_Truth, distance):\n",
    "        jj = 0\n",
    "        distance_sqr = pd.DataFrame(squareform(distance))\n",
    "        for ii in (range(distance_sqr.shape[0])):\n",
    "            the_shortest_dist = distance_sqr.iloc[ii].drop(ii).idxmin()\n",
    "            if Ground_Truth[ii] == Ground_Truth[the_shortest_dist]:\n",
    "                jj += 1 \n",
    "        return ((jj)/distance_sqr.shape[0])\n",
    "      \n",
    "    def matrix_segmentation(self):\n",
    "        seg_mat_list = []\n",
    "        for i in tqdm(range(len(self.sequences)), desc=\"Matrix Segmentation (Splitting based on window size)\", \n",
    "                      disable=1-self.verbose):\n",
    "            sentence = self.sequences[i]\n",
    "            ngrams_  = ngrams(list(sentence), self.n)\n",
    "            for idx, gram in enumerate(ngrams_):\n",
    "                seg_mat_list.append(list(gram + (idx,) + (i,)))\n",
    "        self.seg_mat         = pd.DataFrame(seg_mat_list)\n",
    "        # renaming the column indexes\n",
    "        self.seg_mat.columns = np.append(np.arange(0,self.n-1),('Class', 'Position', 'OriginalMAT_element')) \n",
    "\n",
    "    def finding_the_number_of_clusters(self, HC_tree_terminal_cosine, Dist_tree_terminal_cosine, which_one):\n",
    "        \"\"\"\n",
    "        which_one can take the values of either \"DT\" or \"RF\".\n",
    "        \"\"\"\n",
    "        max_clusters = min(11, len(self.sequences))\n",
    "        ress_sil = []\n",
    "        for i in tqdm(range(2, max_clusters), desc=f\"Finding the best number of clusters ({which_one})\", disable=1-self.verbose):\n",
    "            assignment_tree_terminal_cosine = cluster.hierarchy.cut_tree(HC_tree_terminal_cosine,i).ravel() #.ravel makes it 1D array.\n",
    "            ress_sil.append((silhouette_score(squareform(Dist_tree_terminal_cosine),\n",
    "                                              assignment_tree_terminal_cosine,metric='cosine').round(3)*1000)/1000)\n",
    "        if which_one == 'DT':\n",
    "            self.C_DT = ress_sil.index(max(ress_sil)) + 2\n",
    "        elif which_one == 'RF':\n",
    "            self.C_RF = ress_sil.index(max(ress_sil)) + 2\n",
    "        elif which_one == 'DT_position':\n",
    "            self.C_DT_p = ress_sil.index(max(ress_sil)) + 2\n",
    "        elif which_one == 'RF_position':\n",
    "            self.C_RF_p = ress_sil.index(max(ress_sil)) + 2\n",
    "\n",
    "    def nTreeClus(self):\n",
    "        ############# pre processing #################\n",
    "        if self.n is None:\n",
    "            if self.verbose: print(\"Finding the parameter 'n'\")\n",
    "            min_length = min(map(len, self.sequences))\n",
    "            total_avg  = round(sum( map(len, self.sequences) ) / len(self.sequences)) # average length of strings\n",
    "            self.n     = min(round(total_avg**0.5)+1, min_length-1)\n",
    "            if self.verbose: print(f\"Parameter 'n' is set to {self.n}\")\n",
    "        if (self.n < 3):\n",
    "            raise ValueError(\"\"\"Parameter n could not be less than 3.\n",
    "                                Remove the sequences with the length shorter than 3 and then re-run the function.\"\"\")\n",
    "        \n",
    "        ############# matrix segmentation #################\n",
    "        start_time                    = time.time()\n",
    "        self.matrix_segmentation()\n",
    "        self.running_timeSegmentation = round(time.time() - start_time)\n",
    "\n",
    "        # dummy variable for DT and RF\n",
    "        if self.verbose: print(\"one-hot encoding + x/y train\")\n",
    "        le                            = preprocessing.LabelEncoder()\n",
    "        self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n",
    "        # creating dummy columns for categorical data; one-hot encoding\n",
    "        self.seg_mat                  = pd.get_dummies(self.seg_mat).reset_index(drop=True)\n",
    "        \n",
    "        ############# nTreeClus method using DT #################        \n",
    "        if (self.method in [\"All\",\"DT\"]):\n",
    "            start_time                                   = time.time()\n",
    "            xtrain                                       = self.seg_mat.drop(labels=['OriginalMAT_element', 'Position', 'Class'],\n",
    "                                                                             axis=1).copy()\n",
    "            ytrain                                       = self.seg_mat['Class'].copy()\n",
    "            dtree                                        = DecisionTreeClassifier()\n",
    "            if self.verbose: print(\"Fit DT\")\n",
    "            fitted_tree                                  = dtree.fit(X=xtrain,y=ytrain)\n",
    "            ### finding the terminal nodes.\n",
    "            terminal_tree                                = fitted_tree.tree_.apply(xtrain.values.astype('float32')) #terminal output\n",
    "            if self.verbose: print(\"DataFrame of terminal nodes\")\n",
    "            terminal_output_tree                         = pd.DataFrame(terminal_tree)\n",
    "            terminal_output_tree ['OriginalMAT_element'] = self.seg_mat['OriginalMAT_element'].values\n",
    "            terminal_output_tree.columns                 = ['ter','OriginalMAT_element']\n",
    "            i, r                                         = pd.factorize(terminal_output_tree['OriginalMAT_element'])\n",
    "            j, c                                         = pd.factorize(terminal_output_tree['ter'])\n",
    "            ij, tups                                     = pd.factorize(list(zip(i, j)))\n",
    "            terminal_output_tree_F                       = csr_matrix((np.bincount(ij), tuple(zip(*tups))))\n",
    "            if self.verbose: print(\"Determining the cosine Distance\")\n",
    "            self.Dist_tree_terminal_cosine               = squareform(np.round(1-cosine_similarity(terminal_output_tree_F),\n",
    "                                                                               8))\n",
    "            if self.verbose: print(\"Applying Ward Linkage\")\n",
    "            self.HC_tree_terminal_cosine                 = linkage(self.Dist_tree_terminal_cosine, 'ward')\n",
    "            #finding the number of clusters\n",
    "            if self.C_DT is None:\n",
    "                if self.verbose: print(\"Finding the optimal number of clusters\")\n",
    "                self.finding_the_number_of_clusters(self.HC_tree_terminal_cosine, \n",
    "                                                    self.Dist_tree_terminal_cosine, \"DT\")\n",
    "            # assigning the correct label\n",
    "            if self.verbose: print(\"Cutting The Tree\")\n",
    "            self.assignment_tree_terminal_cosine = cluster.hierarchy.cut_tree(self.HC_tree_terminal_cosine, \n",
    "                                                                              self.C_DT).ravel() #.ravel makes it 1D array.\n",
    "            self.running_timeDT                          = round(time.time() - start_time)\n",
    "            \n",
    "        ############# nTreeClus method using DT + Position #################        \n",
    "        if (self.method in [\"All\",\"DT_position\"]):\n",
    "            start_time                                   = time.time()\n",
    "            xtrain                                       = self.seg_mat.drop(labels=['OriginalMAT_element', 'Class'],\n",
    "                                                                             axis=1).copy()\n",
    "            ytrain                                       = self.seg_mat['Class'].copy()\n",
    "            dtree                                        = DecisionTreeClassifier()\n",
    "            if self.verbose: print(\"Fit DT + POSITION\")\n",
    "            fitted_tree                                  = dtree.fit(X=xtrain,y=ytrain)\n",
    "            ### finding the terminal nodes.\n",
    "            terminal_tree                                = fitted_tree.tree_.apply(xtrain.values.astype('float32')) #terminal output\n",
    "            if self.verbose: print(\"DataFrame of terminal nodes\")\n",
    "            terminal_output_tree                         = pd.DataFrame(terminal_tree)\n",
    "            terminal_output_tree ['OriginalMAT_element'] = self.seg_mat['OriginalMAT_element'].values\n",
    "            terminal_output_tree.columns                 = ['ter','OriginalMAT_element']\n",
    "            i, r                                         = pd.factorize(terminal_output_tree['OriginalMAT_element'])\n",
    "            j, c                                         = pd.factorize(terminal_output_tree['ter'])\n",
    "            ij, tups                                     = pd.factorize(list(zip(i, j)))\n",
    "            terminal_output_tree_F                       = csr_matrix((np.bincount(ij), tuple(zip(*tups))))\n",
    "            if self.verbose: print(\"Determining the cosine Distance\")\n",
    "            self.Dist_tree_terminal_cosine_p               = squareform(np.round(1-cosine_similarity(terminal_output_tree_F),\n",
    "                                                                               8))\n",
    "            if self.verbose: print(\"Applying Ward Linkage\")\n",
    "            self.HC_tree_terminal_cosine_p                 = linkage(self.Dist_tree_terminal_cosine_p, 'ward')\n",
    "            #finding the number of clusters\n",
    "            if self.C_DT_p is None:\n",
    "                if self.verbose: print(\"Finding the optimal number of clusters\")\n",
    "                self.finding_the_number_of_clusters(self.HC_tree_terminal_cosine_p, \n",
    "                                                    self.Dist_tree_terminal_cosine_p, \"DT_position\")\n",
    "            # assigning the correct label\n",
    "            if self.verbose: print(\"Cutting The Tree\")\n",
    "            self.assignment_tree_terminal_cosine_p = cluster.hierarchy.cut_tree(self.HC_tree_terminal_cosine_p,\n",
    "                                                                                self.C_DT_p).ravel() #.ravel makes it 1D array.\n",
    "            self.running_timeDT_p                          = round(time.time() - start_time)\n",
    "            \n",
    "        ############# nTreeClus method using RF #################\n",
    "        if (self.method in [\"All\",\"RF\"]):\n",
    "            start_time                                     = time.time()\n",
    "            xtrain                                         = self.seg_mat.drop(labels=['OriginalMAT_element', 'Position', 'Class'],\n",
    "                                                                               axis=1).copy()\n",
    "            ytrain                                         = self.seg_mat['Class'].copy()\n",
    "            np.random.seed(123)\n",
    "            forest                                         = RandomForestClassifier(n_estimators=self.ntree, max_features=0.36)\n",
    "            if self.verbose: print(\"Fit RF\")\n",
    "            fitted_forest                                  = forest.fit(X=xtrain, y=ytrain)\n",
    "            ### Finding Terminal Nodes\n",
    "            terminal_forest                                = fitted_forest.apply(xtrain) #terminal nodes access\n",
    "            terminal_forest                                = pd.DataFrame(terminal_forest)\n",
    "            #Adding \"columnindex_\" to the beginning of all  \n",
    "            terminal_forest                                = terminal_forest.astype('str')\n",
    "            if self.verbose: print(\"DataFrame of terminal nodes\")\n",
    "            for col in terminal_forest:\n",
    "                terminal_forest[col] = '{}_'.format(col) + terminal_forest[col]\n",
    "            terminal_forest.head()\n",
    "            for i in range(terminal_forest.shape[1]):\n",
    "                if i == 0:\n",
    "                    temp                  = pd.concat([self.seg_mat['OriginalMAT_element'], \n",
    "                                                       terminal_forest[i]], ignore_index=True, axis=1)\n",
    "                    rbind_terminal_forest = temp\n",
    "                else:\n",
    "                    temp                  = pd.concat([self.seg_mat['OriginalMAT_element'], \n",
    "                                                       terminal_forest[i]], ignore_index=True, axis=1)\n",
    "                    rbind_terminal_forest = pd.concat([rbind_terminal_forest, temp], ignore_index=True)\n",
    "            rbind_terminal_forest.columns                 = ['OriginalMAT_element','ter']\n",
    "            i, r                                          = pd.factorize(rbind_terminal_forest['OriginalMAT_element'])\n",
    "            j, c                                          = pd.factorize(rbind_terminal_forest['ter'])\n",
    "            ij, tups                                      = pd.factorize(list(zip(i, j)))\n",
    "            terminal_output_forest_F                      = csr_matrix((np.bincount(ij), tuple(zip(*tups))))\n",
    "            if self.verbose: print(\"Determining the cosine Distance\")\n",
    "            self.Dist_RF_terminal_cosine                  = squareform(np.round(1-cosine_similarity(terminal_output_forest_F),8))\n",
    "            if self.verbose: print(\"Applying Ward Linkage\")\n",
    "            self.HC_RF_terminal_cosine                    = linkage(self.Dist_RF_terminal_cosine, 'ward')\n",
    "            #finding the number of clusters\n",
    "            if self.C_RF is None:\n",
    "                if self.verbose: print(\"Finding the optimal number of clusters\")\n",
    "                self.finding_the_number_of_clusters(self.HC_RF_terminal_cosine, \n",
    "                                                    self.Dist_RF_terminal_cosine, \"RF\")\n",
    "            # assigning the correct label\n",
    "            if self.verbose: print(\"Cutting The Tree\")\n",
    "            self.assignment_RF_terminal_cosine            = cluster.hierarchy.cut_tree(self.HC_RF_terminal_cosine,\n",
    "                                                                                       self.C_RF).ravel() #.ravel makes it 1D array.\n",
    "            self.running_timeRF                           = round(time.time() - start_time)\n",
    "            \n",
    "        ############# nTreeClus method using RF + position #################\n",
    "        if (self.method in [\"All\",\"RF_position\"]):\n",
    "            start_time                                     = time.time()\n",
    "            xtrain                                         = self.seg_mat.drop(labels=['OriginalMAT_element', 'Class'],\n",
    "                                                                            axis=1).copy()\n",
    "            ytrain                                         = self.seg_mat['Class'].copy()\n",
    "            np.random.seed(123)\n",
    "            forest                                         = RandomForestClassifier(n_estimators=self.ntree, max_features=0.36)\n",
    "            if self.verbose: print(\"Fit RF + POSITION\")\n",
    "            fitted_forest                                  = forest.fit(X=xtrain, y=ytrain)\n",
    "            ### Finding Terminal Nodes\n",
    "            terminal_forest                                = fitted_forest.apply(xtrain) #terminal nodes access\n",
    "            terminal_forest                                = pd.DataFrame(terminal_forest)\n",
    "            #Adding \"columnindex_\" to the beginning of all  \n",
    "            terminal_forest                                = terminal_forest.astype('str')\n",
    "            if self.verbose: print(\"DataFrame of terminal nodes\")\n",
    "            for col in terminal_forest:\n",
    "                terminal_forest[col] = '{}_'.format(col) + terminal_forest[col]\n",
    "            terminal_forest.head()\n",
    "            for i in range(terminal_forest.shape[1]):\n",
    "                if i == 0:\n",
    "                    temp                  = pd.concat([self.seg_mat['OriginalMAT_element'], \n",
    "                                                       terminal_forest[i]], ignore_index=True, axis=1)\n",
    "                    rbind_terminal_forest = temp\n",
    "                else:\n",
    "                    temp                  = pd.concat([self.seg_mat['OriginalMAT_element'], \n",
    "                                                       terminal_forest[i]], ignore_index=True, axis=1)\n",
    "                    rbind_terminal_forest = pd.concat([rbind_terminal_forest, temp], ignore_index=True)\n",
    "            rbind_terminal_forest.columns                 = ['OriginalMAT_element','ter']\n",
    "            i, r                                          = pd.factorize(rbind_terminal_forest['OriginalMAT_element'])\n",
    "            j, c                                          = pd.factorize(rbind_terminal_forest['ter'])\n",
    "            ij, tups                                      = pd.factorize(list(zip(i, j)))\n",
    "            terminal_output_forest_F                      = csr_matrix((np.bincount(ij), tuple(zip(*tups))))\n",
    "            if self.verbose: print(\"Determining the cosine Distance\")\n",
    "            self.Dist_RF_terminal_cosine_p                = squareform(np.round(1-cosine_similarity(terminal_output_forest_F),8))\n",
    "            if self.verbose: print(\"Applying Ward Linkage\")\n",
    "            self.HC_RF_terminal_cosine_p                  = linkage(self.Dist_RF_terminal_cosine_p, 'ward')\n",
    "            #finding the number of clusters\n",
    "            if self.C_RF_p is None:\n",
    "                if self.verbose: print(\"Finding the optimal number of clusters\")\n",
    "                self.finding_the_number_of_clusters(self.HC_RF_terminal_cosine_p, \n",
    "                                                    self.Dist_RF_terminal_cosine_p, \"RF_position\")\n",
    "            # assigning the correct label\n",
    "            if self.verbose: print(\"Cutting The Tree\")\n",
    "            self.assignment_RF_terminal_cosine_p          = cluster.hierarchy.cut_tree(self.HC_RF_terminal_cosine_p, \n",
    "                                                                                       self.C_RF_p).ravel() #.ravel makes it 1D array.\n",
    "            self.running_timeRF_p                         = round(time.time() - start_time)\n",
    "\n",
    "    def output(self):\n",
    "        return {\"C_DT\":self.C_DT, \"distance_DT\":self.Dist_tree_terminal_cosine, \n",
    "                \"labels_DT\":self.assignment_tree_terminal_cosine, \n",
    "                \"C_RF\":self.C_RF, \"distance_RF\":self.Dist_RF_terminal_cosine, \n",
    "                \"labels_RF\":self.assignment_RF_terminal_cosine, \n",
    "                \"C_DT_p\":self.C_DT_p, \"distance_DT_p\":self.Dist_tree_terminal_cosine_p, \n",
    "                \"labels_DT_p\":self.assignment_tree_terminal_cosine_p, \n",
    "                \"C_RF_p\":self.C_RF_p, \"distance_RF_p\":self.Dist_RF_terminal_cosine_p, \n",
    "                \"labels_RF_p\":self.assignment_RF_terminal_cosine_p, \n",
    "                \"running_timeSegmentation\": self.running_timeSegmentation, \n",
    "                \"running_timeDT\": self.running_timeDT, \"running_timeDT_p\": self.running_timeDT_p,\n",
    "                \"running_timeRF\": self.running_timeRF, \"running_timeRF_p\": self.running_timeRF_p,\n",
    "                \"Parameter n\":self.n}\n",
    "        \n",
    "    def performance(self, Ground_Truth):\n",
    "        \"\"\"[Reporting the performance]\n",
    "\n",
    "        Args:\n",
    "            Ground_Truth ([list]): [list of ground truth labels]\n",
    "\n",
    "        Returns:\n",
    "            res [pandas DataFrame]: [A dataframe reporting the performance for different metrics]\n",
    "        \"\"\"\n",
    "        self.res = pd.DataFrame()\n",
    "        if (self.method in [\"All\",\"DT\"]):\n",
    "            predictions_DT           = pd.DataFrame({'labels':Ground_Truth, \"labels_DT\":self.assignment_tree_terminal_cosine})\n",
    "            replacement = {}\n",
    "            for i in predictions_DT.labels_DT.unique():\n",
    "                replacement[i] = ((predictions_DT[predictions_DT.labels_DT == i].labels.mode()[0]))\n",
    "            predictions_DT.labels_DT = predictions_DT.labels_DT.map(replacement)\n",
    "            self.res.loc['DT',\"F1S\"] = max(score(Ground_Truth, self.assignment_tree_terminal_cosine, average='macro',zero_division=0)[2], \n",
    "                                    score(Ground_Truth, predictions_DT.labels_DT, average='macro',zero_division=0)[2]).round(3)\n",
    "            self.res.loc['DT',\"ARS\"] = math.ceil((adjusted_rand_score(Ground_Truth, self.assignment_tree_terminal_cosine))*1000)/1000\n",
    "            self.res.loc['DT',\"RS\"]  = math.ceil((self.rand_index_score(Ground_Truth, self.assignment_tree_terminal_cosine))*1000)/1000\n",
    "            self.res.loc['DT',\"Pur\"] = math.ceil((self.purity_score(Ground_Truth, self.assignment_tree_terminal_cosine))*1000)/1000\n",
    "            self.res.loc['DT',\"Sil\"] = math.ceil(silhouette_score(squareform(self.Dist_tree_terminal_cosine),\n",
    "                                                             self.assignment_tree_terminal_cosine,metric='cosine').round(3)*1000)/1000\n",
    "            self.res.loc['DT',\"1NN\"] = math.ceil((self._1nn(Ground_Truth, self.Dist_tree_terminal_cosine))*1000)/1000\n",
    "        if (self.method in [\"All\",\"RF\"]):\n",
    "            predictions_RF = pd.DataFrame({'labels':Ground_Truth, \"labels_RF\":self.assignment_RF_terminal_cosine})\n",
    "            # Update cluster names based on the mode of the truth labels\n",
    "            replacement = {}\n",
    "            for i in predictions_RF.labels_RF.unique():\n",
    "                replacement[i] = ((predictions_RF[predictions_RF.labels_RF == i].labels.mode()[0]))\n",
    "            predictions_RF.labels_RF = predictions_RF.labels_RF.map(replacement)\n",
    "            self.res.loc['RF',\"F1S\"] = max(score(Ground_Truth, self.assignment_RF_terminal_cosine, average='macro',zero_division=0)[2], \n",
    "                                      score(Ground_Truth, predictions_RF.labels_RF, average='macro',zero_division=0)[2]).round(3)\n",
    "            self.res.loc['RF',\"ARS\"] = math.ceil((adjusted_rand_score(Ground_Truth, self.assignment_RF_terminal_cosine))*1000)/1000\n",
    "            self.res.loc['RF',\"RS\"]  = math.ceil((self.rand_index_score(Ground_Truth, self.assignment_RF_terminal_cosine))*1000)/1000\n",
    "            self.res.loc['RF',\"Pur\"] = math.ceil((self.purity_score(Ground_Truth, self.assignment_RF_terminal_cosine))*1000)/1000\n",
    "            self.res.loc['RF',\"Sil\"] = math.ceil(silhouette_score(squareform(self.Dist_RF_terminal_cosine),\n",
    "                                                             self.assignment_RF_terminal_cosine,metric='cosine').round(3)*1000)/1000\n",
    "            self.res.loc['RF',\"1NN\"] = math.ceil((self._1nn(Ground_Truth, self.Dist_RF_terminal_cosine))*1000)/1000\n",
    "        if (self.method in [\"All\",\"DT_position\"]):\n",
    "            predictions_DT = pd.DataFrame({'labels':Ground_Truth, \"labels_DT\":self.assignment_tree_terminal_cosine_p})\n",
    "            replacement = {}\n",
    "            for i in predictions_DT.labels_DT.unique():\n",
    "                replacement[i] = ((predictions_DT[predictions_DT.labels_DT == i].labels.mode()[0]))\n",
    "            predictions_DT.labels_DT = predictions_DT.labels_DT.map(replacement)\n",
    "            self.res.loc['DT_p',\"F1S\"] = max(score(Ground_Truth, self.assignment_tree_terminal_cosine_p, average='macro',zero_division=0)[2], \n",
    "                                    score(Ground_Truth, predictions_DT.labels_DT, average='macro',zero_division=0)[2]).round(3)\n",
    "            self.res.loc['DT_p',\"ARS\"] = math.ceil((adjusted_rand_score(Ground_Truth, self.assignment_tree_terminal_cosine_p))*1000)/1000\n",
    "            self.res.loc['DT_p',\"RS\"]  = math.ceil((self.rand_index_score(Ground_Truth, self.assignment_tree_terminal_cosine_p))*1000)/1000\n",
    "            self.res.loc['DT_p',\"Pur\"] = math.ceil((self.purity_score(Ground_Truth, self.assignment_tree_terminal_cosine_p))*1000)/1000\n",
    "            self.res.loc['DT_p',\"Sil\"] = math.ceil(silhouette_score(squareform(self.Dist_tree_terminal_cosine_p),\n",
    "                                                             self.assignment_tree_terminal_cosine_p,metric='cosine').round(3)*1000)/1000\n",
    "            self.res.loc['DT_p',\"1NN\"] = math.ceil((self._1nn(Ground_Truth, self.Dist_tree_terminal_cosine_p))*1000)/1000\n",
    "        if (self.method in [\"All\",\"RF_position\"]):\n",
    "            predictions_RF = pd.DataFrame({'labels':Ground_Truth, \"labels_RF\":self.assignment_RF_terminal_cosine_p})\n",
    "            # Update cluster names based on the mode of the truth labels\n",
    "            replacement = {}\n",
    "            for i in predictions_RF.labels_RF.unique():\n",
    "                replacement[i] = ((predictions_RF[predictions_RF.labels_RF == i].labels.mode()[0]))\n",
    "            predictions_RF.labels_RF = predictions_RF.labels_RF.map(replacement)\n",
    "            self.res.loc['RF_p',\"F1S\"] = max(score(Ground_Truth, self.assignment_RF_terminal_cosine_p, average='macro',zero_division=0)[2], \n",
    "                                      score(Ground_Truth, predictions_RF.labels_RF, average='macro',zero_division=0)[2]).round(3)\n",
    "            self.res.loc['RF_p',\"ARS\"] = math.ceil((adjusted_rand_score(Ground_Truth, self.assignment_RF_terminal_cosine_p))*1000)/1000\n",
    "            self.res.loc['RF_p',\"RS\"]  = math.ceil((self.rand_index_score(Ground_Truth, self.assignment_RF_terminal_cosine_p))*1000)/1000\n",
    "            self.res.loc['RF_p',\"Pur\"] = math.ceil((self.purity_score(Ground_Truth, self.assignment_RF_terminal_cosine_p))*1000)/1000\n",
    "            self.res.loc['RF_p',\"Sil\"] = math.ceil(silhouette_score(squareform(self.Dist_RF_terminal_cosine_p),\n",
    "                                                             self.assignment_RF_terminal_cosine_p,metric='cosine').round(3)*1000)/1000\n",
    "            self.res.loc['RF_p',\"1NN\"] = math.ceil((self._1nn(Ground_Truth, self.Dist_RF_terminal_cosine_p))*1000)/1000            \n",
    "        return self.res\n",
    "    \n",
    "    def plot(self, which_model, labels, save=False, color_threshold=None, linkage_method= 'ward', annotate = False, xy = (0,0)):\n",
    "        if which_model == 'RF':\n",
    "            distance = self.Dist_RF_terminal_cosine\n",
    "        elif which_model == 'RF_position':\n",
    "            distance = self.Dist_RF_terminal_cosine_p\n",
    "        elif which_model == 'DT':\n",
    "            distance = self.Dist_tree_terminal_cosine\n",
    "        elif which_model == 'DT_position':\n",
    "            distance = self.Dist_tree_terminal_cosine_p\n",
    "        else:\n",
    "            raise Exception(f'Model {which_model} not supported.')\n",
    "        HC_tree_terminal_cosine = linkage(distance, linkage_method)\n",
    "        fig = plt.figure(figsize=(25, 10))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        if color_threshold == None:\n",
    "            dendrogram(HC_tree_terminal_cosine,labels=labels, ax=ax)\n",
    "        else:\n",
    "            dendrogram(HC_tree_terminal_cosine,labels=labels, ax=ax, color_threshold=color_threshold)            \n",
    "        ax.tick_params(axis='x', which='major', labelsize=18, rotation=90)\n",
    "        ax.tick_params(axis='y', which='major', labelsize=18)\n",
    "        if annotate:\n",
    "            ax.annotate(f\"\"\"\n",
    "                        F1-score = {round(self.res.loc['DT_p', 'F1S'],2)}\n",
    "                        ARS        = {round(self.res.loc['DT_p', 'ARS'],2)}\n",
    "                        RS          = {round(self.res.loc['DT_p', 'RS'],2)}\n",
    "                        Purity     = {round(self.res.loc['DT_p', 'Pur'],2)}\n",
    "                        ASW       = {round(self.res.loc['DT_p', 'Sil'],2)}\n",
    "                        1NN       = {round(self.res.loc['DT_p', '1NN'],2)}            \n",
    "                        \"\"\", xy=xy, xytext =(0, 0), fontsize=18, \n",
    "                        textcoords='offset points', va='top', ha='left')        \n",
    "        if save:\n",
    "            plt.savefig(f\"dendrogram_{which_model}.png\", dpi=300, bbox_inches='tight')        \n",
    "        return fig, ax\n",
    "    \n",
    "    def __version__(self):\n",
    "        print('1.2.1')\n",
    "    \n",
    "    def updates(self):\n",
    "        print(\"\"\"\n",
    "              - Adding Plotting option\n",
    "              - Adding Executing time.\n",
    "              - Adding positional version of nTreeClus \n",
    "              - Adding 1NN to the performance metrics\n",
    "              - Fixing Some bugs in performance calculation\n",
    "              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a025a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ischair    crs odepartment       action position         type  \\\n",
      "0       TRUE  cs602          ee         read    staff       roster   \n",
      "1       TRUE  ee601          cs         read  advisor   transcript   \n",
      "2         na  ee101   registrar    setstatus  advisor  application   \n",
      "3         na  cs602  admissions     addscore  faculty  application   \n",
      "4      FALSE  cs602          ce         read  faculty   transcript   \n",
      "...      ...    ...         ...          ...      ...          ...   \n",
      "5995    TRUE  cs101          ee  changescore  faculty    gradebook   \n",
      "5996    TRUE  ee101          ee  changescore  faculty    gradebook   \n",
      "5997    TRUE  cs602          ee  changescore  faculty    gradebook   \n",
      "5998    TRUE  cs602          ee  changescore  faculty    gradebook   \n",
      "5999    TRUE  cs601          ee  changescore  faculty    gradebook   \n",
      "\n",
      "     udepartment crstaught crstaken  \\\n",
      "0             ee     cs601    cs602   \n",
      "1      registrar     ee101    cs601   \n",
      "2     admissions     ee601    ee101   \n",
      "3             ee     ee601    cs602   \n",
      "4      registrar     ee101    cs101   \n",
      "...          ...       ...      ...   \n",
      "5995          cs     cs101    ee101   \n",
      "5996          cs     ee101    cs602   \n",
      "5997          cs     cs602    cs602   \n",
      "5998          cs     cs602    ee601   \n",
      "5999          cs     cs601    cs101   \n",
      "\n",
      "                                                 concat  \n",
      "0                TRUEcs602eereadstaffrostereecs601cs602  \n",
      "1     TRUEee601csreadadvisortranscriptregistraree101...  \n",
      "2     naee101registrarsetstatusadvisorapplicationadm...  \n",
      "3     nacs602admissionsaddscorefacultyapplicationeee...  \n",
      "4     FALSEcs602cereadfacultytranscriptregistraree10...  \n",
      "...                                                 ...  \n",
      "5995  TRUEcs101eechangescorefacultygradebookcscs101e...  \n",
      "5996  TRUEee101eechangescorefacultygradebookcsee101c...  \n",
      "5997  TRUEcs602eechangescorefacultygradebookcscs602c...  \n",
      "5998  TRUEcs602eechangescorefacultygradebookcscs602e...  \n",
      "5999  TRUEcs601eechangescorefacultygradebookcscs601c...  \n",
      "\n",
      "[6000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "def concat_strings(row):\n",
    "    return ''.join(row)\n",
    "\n",
    "# 使用apply()方法和lambda表达式对每一行的数据进行处理\n",
    "data = df\n",
    "data['concat'] = data.apply(lambda row: concat_strings(row), axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddeff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 23296.66it/s]\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n",
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 20.502262353897095 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 66100.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 52.56512784957886 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 6193.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 57.20030117034912 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 67961.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 19.142507791519165 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 55364.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 18.900509357452393 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 71307.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 18.683255672454834 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 29988.30it/s]\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n",
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 19.072103023529053 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 62519.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 19.028996467590332 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 24372.33it/s]\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n",
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 19.248244047164917 seconds ---\n",
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████| 6000/6000 [00:00<00:00, 30081.11it/s]\n",
      "C:\\Users\\52543\\AppData\\Local\\Temp\\ipykernel_29628\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n",
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n",
      "--- 19.194772243499756 seconds ---\n",
      "20.502262353897095\n",
      "52.56512784957886\n",
      "57.20030117034912\n",
      "19.142507791519165\n",
      "18.900509357452393\n",
      "18.683255672454834\n",
      "19.072103023529053\n",
      "19.028996467590332\n",
      "19.248244047164917\n",
      "19.194772243499756\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "result = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    model = nTreeClus(list(data.concat), n=None, ntree=10, method=\"RF\", verbose=1, C=i)\n",
    "    model.nTreeClus()\n",
    "    result.append(time.time() - start_time)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "for i in range(10):\n",
    "    print(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3a7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ischair    crs odepartment       action position         type  \\\n",
      "0      FALSE  ee601          cs         read  faculty       roster   \n",
      "1      FALSE  cs101          ee         read  faculty       roster   \n",
      "2       TRUE  ee601          cs         read  advisor   transcript   \n",
      "3       TRUE  ee101          cs         read  advisor   transcript   \n",
      "4       TRUE  cs101   registrar         read    staff  application   \n",
      "...      ...    ...         ...          ...      ...          ...   \n",
      "7995   FALSE  ee101  admissions  changescore  faculty    gradebook   \n",
      "7996   FALSE  ee601          cs  changescore  faculty    gradebook   \n",
      "7997      na  cs602  admissions  changescore  faculty    gradebook   \n",
      "7998    TRUE  ee601   registrar  changescore  faculty    gradebook   \n",
      "7999    TRUE  ee601          ce  changescore  faculty    gradebook   \n",
      "\n",
      "     udepartment crstaught crstaken  \\\n",
      "0      registrar     ee101    ee601   \n",
      "1             ce     ee601    cs101   \n",
      "2      registrar     ee101    cs602   \n",
      "3             ce     cs101    cs101   \n",
      "4     admissions     cs101    ee101   \n",
      "...          ...       ...      ...   \n",
      "7995          ce     cs602    ee101   \n",
      "7996          ee     cs602    ee601   \n",
      "7997          ce     ee601    cs602   \n",
      "7998          ee     cs101    ee601   \n",
      "7999   registrar     cs101    ee601   \n",
      "\n",
      "                                                 concat  label  \n",
      "0      FALSEee601csreadfacultyrosterregistraree101ee601      0  \n",
      "1             FALSEcs101eereadfacultyrosterceee601cs101      0  \n",
      "2     TRUEee601csreadadvisortranscriptregistraree101...      1  \n",
      "3          TRUEee101csreadadvisortranscriptcecs101cs101      1  \n",
      "4     TRUEcs101registrarreadstaffapplicationadmissio...      2  \n",
      "...                                                 ...    ...  \n",
      "7995  FALSEee101admissionschangescorefacultygradeboo...      7  \n",
      "7996  FALSEee601cschangescorefacultygradebookeecs602...      7  \n",
      "7997  nacs602admissionschangescorefacultygradebookce...      7  \n",
      "7998  TRUEee601registrarchangescorefacultygradebooke...      7  \n",
      "7999  TRUEee601cechangescorefacultygradebookregistra...      7  \n",
      "\n",
      "[8000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data['label'] = model.output()['labels_RF']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821c78de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ischair</th>\n",
       "      <th>crs</th>\n",
       "      <th>odepartment</th>\n",
       "      <th>action</th>\n",
       "      <th>position</th>\n",
       "      <th>type</th>\n",
       "      <th>udepartment</th>\n",
       "      <th>crstaught</th>\n",
       "      <th>crstaken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs</td>\n",
       "      <td>read</td>\n",
       "      <td>faculty</td>\n",
       "      <td>roster</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee101</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>cs101</td>\n",
       "      <td>ee</td>\n",
       "      <td>read</td>\n",
       "      <td>faculty</td>\n",
       "      <td>roster</td>\n",
       "      <td>ce</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs</td>\n",
       "      <td>read</td>\n",
       "      <td>advisor</td>\n",
       "      <td>transcript</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee101</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>ee101</td>\n",
       "      <td>cs</td>\n",
       "      <td>read</td>\n",
       "      <td>advisor</td>\n",
       "      <td>transcript</td>\n",
       "      <td>ce</td>\n",
       "      <td>cs101</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>cs101</td>\n",
       "      <td>registrar</td>\n",
       "      <td>read</td>\n",
       "      <td>staff</td>\n",
       "      <td>application</td>\n",
       "      <td>admissions</td>\n",
       "      <td>cs101</td>\n",
       "      <td>ee101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>ee101</td>\n",
       "      <td>admissions</td>\n",
       "      <td>changescore</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ce</td>\n",
       "      <td>cs602</td>\n",
       "      <td>ee101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs</td>\n",
       "      <td>changescore</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ee</td>\n",
       "      <td>cs602</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>na</td>\n",
       "      <td>cs602</td>\n",
       "      <td>admissions</td>\n",
       "      <td>changescore</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ce</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>ee601</td>\n",
       "      <td>registrar</td>\n",
       "      <td>changescore</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ee</td>\n",
       "      <td>cs101</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>ee601</td>\n",
       "      <td>ce</td>\n",
       "      <td>changescore</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>cs101</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ischair    crs odepartment       action position         type  \\\n",
       "0      FALSE  ee601          cs         read  faculty       roster   \n",
       "1      FALSE  cs101          ee         read  faculty       roster   \n",
       "2       TRUE  ee601          cs         read  advisor   transcript   \n",
       "3       TRUE  ee101          cs         read  advisor   transcript   \n",
       "4       TRUE  cs101   registrar         read    staff  application   \n",
       "...      ...    ...         ...          ...      ...          ...   \n",
       "7995   FALSE  ee101  admissions  changescore  faculty    gradebook   \n",
       "7996   FALSE  ee601          cs  changescore  faculty    gradebook   \n",
       "7997      na  cs602  admissions  changescore  faculty    gradebook   \n",
       "7998    TRUE  ee601   registrar  changescore  faculty    gradebook   \n",
       "7999    TRUE  ee601          ce  changescore  faculty    gradebook   \n",
       "\n",
       "     udepartment crstaught crstaken  \n",
       "0      registrar     ee101    ee601  \n",
       "1             ce     ee601    cs101  \n",
       "2      registrar     ee101    cs602  \n",
       "3             ce     cs101    cs101  \n",
       "4     admissions     cs101    ee101  \n",
       "...          ...       ...      ...  \n",
       "7995          ce     cs602    ee101  \n",
       "7996          ee     cs602    ee601  \n",
       "7997          ce     ee601    cs602  \n",
       "7998          ee     cs101    ee601  \n",
       "7999   registrar     cs101    ee601  \n",
       "\n",
       "[8000 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata=data.drop(columns='concat')\n",
    "ndata=ndata.drop(columns='label')\n",
    "ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08add0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.9396722316741943 seconds ---\n",
      "34\n",
      "{0: {'action': 'read', 'position': 'faculty', 'type': 'roster', 'crstaken': 'crs'}, 1: {'ischair': 'TRUE', 'action': 'read', 'type': 'transcript'}, 2: {'action': 'read', 'type': 'application', 'udepartment': 'admissions'}, 3: {'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 4: {'action': 'checkstatus', 'position': 'student', 'type': 'application'}, 5: {'action': 'addscore', 'type': 'gradebook', 'crstaken': 'crstaught'}, 6: {'action': 'read', 'type': 'roster', 'udepartment': 'registrar'}, 7: {'action': 'changescore', 'position': 'faculty', 'type': 'gradebook', 'crstaken': 'crs'}, 8: {'action': 'readmyscores', 'type': 'gradebook', 'crstaken': 'crs'}, 9: {'odepartment': 'admissions', 'action': 'read', 'position': 'faculty', 'type': 'roster', 'crstaken': 'crs'}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "#print(datafreq)\n",
    "clusTemp = pd.DataFrame()\n",
    "\n",
    "policy ={}\n",
    "###change FN: p, FP: d or act\n",
    "datasize= len(act.index)\n",
    "#print(\"{\")\n",
    "for i in range(model.output()['C_RF']):\n",
    "    policy[i] = {}\n",
    "    \n",
    "    clusTemp = ndata.loc[data['label'] == i]\n",
    "    #clusTemp = FN.loc[FN['cluster'] == i]\n",
    "    clussize= len(clusTemp.index)\n",
    "    #print(i,\":{\",sep='',end=\"\")\n",
    "    #print(clusTemp.describe())\n",
    "    for col in ndata.columns:\n",
    "        #actual data:  act[col].value_counts().to_dict()\n",
    "        # FN data: p[col].value_counts().to_dict()\n",
    "        # FP data: d[col].value_counts().to_dict()\n",
    "        datafreq =   act[col].value_counts().to_dict() # act[col].value_counts().to_dict()#\n",
    "#         print(datafreq)\n",
    "        #datafreq= pd.DataFrame.from_dict(datafreq, )\n",
    "        temp=clusTemp[col].value_counts().to_dict()\n",
    "#         print(temp)\n",
    "        for key, value in datafreq.items():\n",
    "            \n",
    "            \n",
    "            for key1, value1 in temp.items():\n",
    "#                 print(key, key1)\n",
    "                if key == key1:\n",
    "                    #print(key ,value,value1)\n",
    "                    x = value1/datasize\n",
    "                    y = value1/clussize\n",
    "                    #print((y-x))\n",
    "                    #if key in centroids[i]:\n",
    "                    # 在这里调整阈值\n",
    "                    if (y-x) >= 0.549:\n",
    "                        if col not in policy[i]:\n",
    "                            policy[i][col] = key\n",
    "                    for col2 in ndata.columns:\n",
    "                                if col !=col2:\n",
    "                                    clusTemp = ndata.loc[data['label'] == i]\n",
    "#                                     clus = clusTemp.loc[clusTemp[col] == clusTemp[col2]]\n",
    "                                    clus = clusTemp.loc[clusTemp[col].astype(str) == clusTemp[col2].astype(str)]\n",
    "                                    if len(clus) >= len(clusTemp)/2:\n",
    "                                        #print(\"'\",col,\"':'\",col2,\"',\",sep='',end=\"\")\n",
    "                                        if col not in policy[i] and col2 not in policy[i]: \n",
    "                                            policy[i][col] = col2\n",
    "                                        else:\n",
    "                                            if col in policy[i]: \n",
    "                                                policy[i][col] = col2\n",
    "                                            if col2 in policy[i] :\n",
    "                                                del policy[i][col2]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "print(sum(len(v) for v in policy.values()))\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f955134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 9  score = 0.8 5 4\n",
      "{'action', 'crstaken', 'type', 'position'} \n",
      " defaultdict(<class 'list'>, {'action': ['read', 'read'], 'position': ['faculty', 'faculty'], 'type': ['roster', 'roster'], 'crstaken': ['crs', 'crs'], 'odepartment': ['admissions']})\n",
      "9 , 0  score = 0.8 5 4\n",
      "{'action', 'crstaken', 'type', 'position'} \n",
      " defaultdict(<class 'list'>, {'odepartment': ['admissions'], 'action': ['read', 'read'], 'position': ['faculty', 'faculty'], 'type': ['roster', 'roster'], 'crstaken': ['crs', 'crs']})\n",
      "{0: {'action': 'read', 'position': 'faculty', 'type': 'roster', 'crstaken': 'crs'}, 1: {'ischair': 'TRUE', 'action': 'read', 'type': 'transcript'}, 2: {'action': 'read', 'type': 'application', 'udepartment': 'admissions'}, 3: {'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 4: {'action': 'checkstatus', 'position': 'student', 'type': 'application'}, 5: {'action': 'addscore', 'type': 'gradebook', 'crstaken': 'crstaught'}, 6: {'action': 'read', 'type': 'roster', 'udepartment': 'registrar'}, 7: {'action': 'changescore', 'position': 'faculty', 'type': 'gradebook', 'crstaken': 'crs'}, 8: {'action': 'readmyscores', 'type': 'gradebook', 'crstaken': 'crs'}, 9: {'odepartment': 'admissions', 'action': 'read', 'position': 'faculty', 'type': 'roster', 'crstaken': 'crs'}}\n"
     ]
    }
   ],
   "source": [
    "## clean extracted policy by findsimilar rules and clean them\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "rules = policy\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = (set(list1.values()).intersection(list2.values()))\n",
    "    #print(list(set(list1).intersection(list2)))\n",
    "    union = defaultdict(list)\n",
    "    for k, v in chain(list1.items(), list2.items()):\n",
    "        #if v not in intersection:\n",
    "            union[k].append(v)\n",
    "    #print(union)    \n",
    "    \n",
    "    intersectionl = len(intersection)\n",
    "    unionl = len(union)\n",
    "    if unionl == 0:\n",
    "        score = 0.0\n",
    "        return \n",
    "    else:\n",
    "        score = float(intersectionl / unionl)\n",
    "    if score > 0.7:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",key2,\" score =\", score,unionl,intersectionl)\n",
    "                print( (set(list1).intersection(list2)),\"\\n\" ,union)\n",
    "                #print(intersectionl)\n",
    "    return float(intersectionl / unionl)\n",
    "\n",
    "for key, value in policy.items():\n",
    "    \n",
    "    for key2, v  in rules.items():\n",
    "    #print(key, value)\n",
    "        \n",
    "        if key !=key2:\n",
    "            \n",
    "            #print(key, key2)\n",
    "            \"\"\"for z, j in value.items():\n",
    "                for y, i in v.items():\n",
    "                     if z == y:\"\"\"\n",
    "            #score = jaccard_similarity_score(value, v)\n",
    "            score = jaccard_similarity(value, v)\n",
    "                        #print(i,j)\n",
    "            \"\"\"if score > 0.6:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",k,\" score =\", score)\n",
    "    \"\"\"\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0697a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ischair    crs odepartment       action position         type  \\\n",
      "0       FALSE  ee601          cs         read  faculty       roster   \n",
      "1       FALSE  cs101          ee         read  faculty       roster   \n",
      "2        TRUE  ee601          cs         read  advisor   transcript   \n",
      "3        TRUE  ee101          cs         read  advisor   transcript   \n",
      "4        TRUE  cs101   registrar         read    staff  application   \n",
      "...       ...    ...         ...          ...      ...          ...   \n",
      "15996      na  ee101          ee    setstatus    staff       roster   \n",
      "15997    TRUE  ee101   registrar        write  faculty    gradebook   \n",
      "15998    TRUE  ee101          cs         read  faculty    gradebook   \n",
      "15999    TRUE  ee101   registrar  changescore    staff   transcript   \n",
      "16000      na  ee101  admissions    setstatus    staff   transcript   \n",
      "\n",
      "      udepartment crstaught crstaken class lable  \n",
      "0       registrar     ee101    ee601     p     p  \n",
      "1              ce     ee601    cs101     p     p  \n",
      "2       registrar     ee101    cs602     p     p  \n",
      "3              ce     cs101    cs101     p     p  \n",
      "4      admissions     cs101    ee101     p     p  \n",
      "...           ...       ...      ...   ...   ...  \n",
      "15996          ee     cs101    cs601     d     d  \n",
      "15997   registrar     ee601    cs602     d     d  \n",
      "15998          ee     cs101    cs602     d     d  \n",
      "15999  admissions     cs602    ee101     d     d  \n",
      "16000          ee     cs602    ee601     d     d  \n",
      "\n",
      "[16001 rows x 11 columns]\n",
      "--- 0.5192523002624512 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# run the extracted policy over the complete data\n",
    "import time\n",
    "def dict_compare(d1, d2):\n",
    "    d1_keys = set(d1.keys())\n",
    "    d2_keys = set(d2.keys())\n",
    "\n",
    "    intersect_keys = d1_keys.intersection(d2_keys)\n",
    " \n",
    "    relation = []\n",
    "    added = d1_keys - d2_keys\n",
    "    removed = d2_keys - d1_keys\n",
    "  \n",
    "    same = set(o for o in intersect_keys if  d1[o] in d2[o] )\n",
    "   \n",
    "    if len(same) == len(intersect_keys):\n",
    "        return added, removed, same, relation\n",
    "    for key,  o in d2.items():\n",
    "        if type(o) == str:\n",
    "                \n",
    " \n",
    "            temp = set(i for i in intersect_keys if type(d2[i]) == str and d2[i] in d1_keys and d1[i] == d1[d2[i]] )\n",
    "                #print(temp)\n",
    "            if len(temp)>0:\n",
    "                    relation = temp\n",
    "        \n",
    "           \n",
    "    return added, removed, same, relation\n",
    "\n",
    "\n",
    "def ruleCheck (row):\n",
    "    lable = 'd'\n",
    "    drow = row.to_dict()\n",
    "    \n",
    "    for key,value in policy.items():\n",
    "        #print(key)\n",
    "#         返回策略与本条数据比较的结果，包括有多少值相等，满足多少属性关系\n",
    "        added, removed, same, relation = dict_compare(drow, value)\n",
    "#         这行是关键，比较是否满足策略，比较满足的属性值与属性关系是否能比全部值的数量多，如果多，则全覆盖了，通过\n",
    "        if len(same)+len(relation) >= len(value) or len(same) == len(value):\n",
    "            #print(len(same)+len(relation), len(value))\n",
    "            lable = \"p\"\n",
    "#             row ['lable'] ='p'\n",
    "            return lable\n",
    "    \n",
    "    return lable\n",
    "start_time = time.time()\n",
    "\n",
    "act['lable'] = act.apply(ruleCheck, axis=1)\n",
    "print(act)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88f9d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN= 0 , FP= 121 , TP= 8000 , TN= 7880\n",
      "recall = 100.0 \n",
      "precession = 98.51003570988794 \n",
      "accuracy =  99.24379726267108 \n",
      "f-score =  99.2494262142547\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "log = act[(act['class'] == \"p\") & (act['lable'] == \"p\")]\n",
    "log2 = act[(act['class'] == \"d\") & (act['lable'] == \"d\")]\n",
    "FN = act[(act['class'] == \"p\") & (act['lable'] == \"d\")]\n",
    "FP = act[(act['class'] == \"d\") & (act['lable'] == \"p\")]\n",
    "\n",
    "p = act[act['class'] == \"p\"]\n",
    "d = act[act['class'] == \"d\"]\n",
    "#[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "#print(len(log),'\\n', log.head(10))\n",
    "#print(FN.describe(),FP.describe(),log2.describe(),d.describe())\n",
    "#log.describe()\n",
    "print(\"FN=\", len(FN), \", FP=\", len(FP), \", TP=\", len(log), \", TN=\", len(log2))\n",
    "recall = (len(log)/(len(log)+len(FN)))*100\n",
    "precesion = (len(log)/(len(log)+len(FP)))*100\n",
    "accu = ((len(log)+len(log2))/len(act))*100\n",
    "f = 2*((recall*precesion)/(recall+precesion))\n",
    "print(\"recall =\",recall, \"\\nprecession =\",precesion, \"\\naccuracy = \", accu,\"\\nf-score = \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e164adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ischair    crs odepartment        action position         type  \\\n",
      "0       TRUE  cs101   registrar          read    staff  application   \n",
      "1         na  ee601          ee  readmyscores  advisor    gradebook   \n",
      "2         na  cs602   registrar          read  faculty  application   \n",
      "3         na  ee101  admissions          read  advisor  application   \n",
      "4         na  cs101  admissions          read  student  application   \n",
      "...      ...    ...         ...           ...      ...          ...   \n",
      "1986      na  cs101   registrar  readmyscores    staff    gradebook   \n",
      "1987      na  cs101   registrar  readmyscores  advisor    gradebook   \n",
      "1988   FALSE  cs602   registrar  readmyscores    staff    gradebook   \n",
      "1989    TRUE  ee601          ee  readmyscores  faculty    gradebook   \n",
      "1990   FALSE  cs602          ee  readmyscores  student    gradebook   \n",
      "\n",
      "     udepartment crstaught crstaken  \\\n",
      "0     admissions     cs101    ee101   \n",
      "1      registrar     ee601    ee601   \n",
      "2     admissions     cs101    cs101   \n",
      "3     admissions     ee601    cs101   \n",
      "4     admissions     ee601    cs101   \n",
      "...          ...       ...      ...   \n",
      "1986          cs     ee601    cs101   \n",
      "1987          ce     cs101    cs101   \n",
      "1988   registrar     ee101    cs602   \n",
      "1989          ee     cs601    ee601   \n",
      "1990   registrar     cs101    cs602   \n",
      "\n",
      "                                                 concat  \n",
      "0     TRUEcs101registrarreadstaffapplicationadmissio...  \n",
      "1     naee601eereadmyscoresadvisorgradebookregistrar...  \n",
      "2     nacs602registrarreadfacultyapplicationadmissio...  \n",
      "3     naee101admissionsreadadvisorapplicationadmissi...  \n",
      "4     nacs101admissionsreadstudentapplicationadmissi...  \n",
      "...                                                 ...  \n",
      "1986  nacs101registrarreadmyscoresstaffgradebookcsee...  \n",
      "1987  nacs101registrarreadmyscoresadvisorgradebookce...  \n",
      "1988  FALSEcs602registrarreadmyscoresstaffgradebookr...  \n",
      "1989  TRUEee601eereadmyscoresfacultygradebookeecs601...  \n",
      "1990  FALSEcs602eereadmyscoresstudentgradebookregist...  \n",
      "\n",
      "[1991 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "def concat_strings(row):\n",
    "    return ''.join(row)\n",
    "\n",
    "# 使用apply()方法和lambda表达式对每一行的数据进行处理\n",
    "data1 =  FN.drop(columns=['class','lable']).reset_index() #FN.drop(columns=['class','lable']) #FP.drop(columns=['class','lable'])#ReFN.drop(columns=['class','lable','lable1','lable2']) #ReFN.drop(columns=['class','lable','lable1']).reset_index() #FN.drop(columns=['class','lable']) #df\n",
    "data1 = data1.drop(columns=['index'])\n",
    "data1['concat'] = data1.apply(lambda row: concat_strings(row), axis=1)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce234644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|██████████████████| 1991/1991 [00:00<00:00, 17770.70it/s]\n",
      "C:\\Users\\s's'y\\AppData\\Local\\Temp\\ipykernel_29568\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n",
      "Fit RF\n",
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n"
     ]
    }
   ],
   "source": [
    "# FN\n",
    "model1 = nTreeClus(list(data1.concat), n=None, ntree=10, method=\"RF\", verbose=1, C=10)\n",
    "model1.nTreeClus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e5ca4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ischair    crs odepartment        action position         type  \\\n",
      "0       TRUE  cs101   registrar          read    staff  application   \n",
      "1         na  ee601          ee  readmyscores  advisor    gradebook   \n",
      "2         na  cs602   registrar          read  faculty  application   \n",
      "3         na  ee101  admissions          read  advisor  application   \n",
      "4         na  cs101  admissions          read  student  application   \n",
      "...      ...    ...         ...           ...      ...          ...   \n",
      "1986      na  cs101   registrar  readmyscores    staff    gradebook   \n",
      "1987      na  cs101   registrar  readmyscores  advisor    gradebook   \n",
      "1988   FALSE  cs602   registrar  readmyscores    staff    gradebook   \n",
      "1989    TRUE  ee601          ee  readmyscores  faculty    gradebook   \n",
      "1990   FALSE  cs602          ee  readmyscores  student    gradebook   \n",
      "\n",
      "     udepartment crstaught crstaken  \\\n",
      "0     admissions     cs101    ee101   \n",
      "1      registrar     ee601    ee601   \n",
      "2     admissions     cs101    cs101   \n",
      "3     admissions     ee601    cs101   \n",
      "4     admissions     ee601    cs101   \n",
      "...          ...       ...      ...   \n",
      "1986          cs     ee601    cs101   \n",
      "1987          ce     cs101    cs101   \n",
      "1988   registrar     ee101    cs602   \n",
      "1989          ee     cs601    ee601   \n",
      "1990   registrar     cs101    cs602   \n",
      "\n",
      "                                                 concat  label  \n",
      "0     TRUEcs101registrarreadstaffapplicationadmissio...      0  \n",
      "1     naee601eereadmyscoresadvisorgradebookregistrar...      1  \n",
      "2     nacs602registrarreadfacultyapplicationadmissio...      0  \n",
      "3     naee101admissionsreadadvisorapplicationadmissi...      2  \n",
      "4     nacs101admissionsreadstudentapplicationadmissi...      3  \n",
      "...                                                 ...    ...  \n",
      "1986  nacs101registrarreadmyscoresstaffgradebookcsee...      1  \n",
      "1987  nacs101registrarreadmyscoresadvisorgradebookce...      1  \n",
      "1988  FALSEcs602registrarreadmyscoresstaffgradebookr...      1  \n",
      "1989  TRUEee601eereadmyscoresfacultygradebookeecs601...      8  \n",
      "1990  FALSEcs602eereadmyscoresstudentgradebookregist...      1  \n",
      "\n",
      "[1991 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data1['label'] = model1.output()['labels_RF']\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52907f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ischair</th>\n",
       "      <th>crs</th>\n",
       "      <th>odepartment</th>\n",
       "      <th>action</th>\n",
       "      <th>position</th>\n",
       "      <th>type</th>\n",
       "      <th>udepartment</th>\n",
       "      <th>crstaught</th>\n",
       "      <th>crstaken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>cs101</td>\n",
       "      <td>registrar</td>\n",
       "      <td>read</td>\n",
       "      <td>staff</td>\n",
       "      <td>application</td>\n",
       "      <td>admissions</td>\n",
       "      <td>cs101</td>\n",
       "      <td>ee101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>ee601</td>\n",
       "      <td>ee</td>\n",
       "      <td>readmyscores</td>\n",
       "      <td>advisor</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee601</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>cs602</td>\n",
       "      <td>registrar</td>\n",
       "      <td>read</td>\n",
       "      <td>faculty</td>\n",
       "      <td>application</td>\n",
       "      <td>admissions</td>\n",
       "      <td>cs101</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>ee101</td>\n",
       "      <td>admissions</td>\n",
       "      <td>read</td>\n",
       "      <td>advisor</td>\n",
       "      <td>application</td>\n",
       "      <td>admissions</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>cs101</td>\n",
       "      <td>admissions</td>\n",
       "      <td>read</td>\n",
       "      <td>student</td>\n",
       "      <td>application</td>\n",
       "      <td>admissions</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>na</td>\n",
       "      <td>cs101</td>\n",
       "      <td>registrar</td>\n",
       "      <td>readmyscores</td>\n",
       "      <td>staff</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>cs</td>\n",
       "      <td>ee601</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>na</td>\n",
       "      <td>cs101</td>\n",
       "      <td>registrar</td>\n",
       "      <td>readmyscores</td>\n",
       "      <td>advisor</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ce</td>\n",
       "      <td>cs101</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>cs602</td>\n",
       "      <td>registrar</td>\n",
       "      <td>readmyscores</td>\n",
       "      <td>staff</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee101</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>ee601</td>\n",
       "      <td>ee</td>\n",
       "      <td>readmyscores</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ee</td>\n",
       "      <td>cs601</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>cs602</td>\n",
       "      <td>ee</td>\n",
       "      <td>readmyscores</td>\n",
       "      <td>student</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>cs101</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ischair    crs odepartment        action position         type  \\\n",
       "0       TRUE  cs101   registrar          read    staff  application   \n",
       "1         na  ee601          ee  readmyscores  advisor    gradebook   \n",
       "2         na  cs602   registrar          read  faculty  application   \n",
       "3         na  ee101  admissions          read  advisor  application   \n",
       "4         na  cs101  admissions          read  student  application   \n",
       "...      ...    ...         ...           ...      ...          ...   \n",
       "1986      na  cs101   registrar  readmyscores    staff    gradebook   \n",
       "1987      na  cs101   registrar  readmyscores  advisor    gradebook   \n",
       "1988   FALSE  cs602   registrar  readmyscores    staff    gradebook   \n",
       "1989    TRUE  ee601          ee  readmyscores  faculty    gradebook   \n",
       "1990   FALSE  cs602          ee  readmyscores  student    gradebook   \n",
       "\n",
       "     udepartment crstaught crstaken  \n",
       "0     admissions     cs101    ee101  \n",
       "1      registrar     ee601    ee601  \n",
       "2     admissions     cs101    cs101  \n",
       "3     admissions     ee601    cs101  \n",
       "4     admissions     ee601    cs101  \n",
       "...          ...       ...      ...  \n",
       "1986          cs     ee601    cs101  \n",
       "1987          ce     cs101    cs101  \n",
       "1988   registrar     ee101    cs602  \n",
       "1989          ee     cs601    ee601  \n",
       "1990   registrar     cs101    cs602  \n",
       "\n",
       "[1991 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata1=data1.drop(columns='concat')\n",
    "ndata1=ndata1.drop(columns='label')\n",
    "ndata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63aafc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.893733978271484 seconds ---\n",
      "{0: {'odepartment': 'registrar', 'action': 'read', 'type': 'application', 'udepartment': 'admissions'}, 1: {'odepartment': 'registrar', 'action': 'readmyscores', 'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crs'}, 2: {'action': 'read', 'position': 'advisor', 'type': 'application', 'udepartment': 'admissions'}, 3: {'action': 'read', 'position': 'student', 'type': 'application', 'udepartment': 'admissions'}, 4: {'action': 'readmyscores', 'type': 'gradebook', 'crstaken': 'crs'}, 5: {'action': 'readmyscores', 'position': 'advisor', 'type': 'gradebook', 'crstaken': 'crs'}, 6: {'action': 'read', 'position': 'staff', 'type': 'application', 'udepartment': 'admissions'}, 7: {'action': 'readmyscores', 'type': 'gradebook', 'udepartment': 'admissions', 'crstaken': 'crs'}, 8: {'action': 'readmyscores', 'position': 'faculty', 'type': 'gradebook', 'crstaken': 'crs'}, 9: {'action': 'read', 'position': 'faculty', 'type': 'application', 'udepartment': 'admissions'}}\n"
     ]
    }
   ],
   "source": [
    "# Calculating FN Attributes Effectevness in each cluster\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "#print(datafreq)\n",
    "clusTemp = pd.DataFrame()\n",
    "\n",
    "FNpolicy ={}\n",
    "###change FN: p, FP: d or act\n",
    "datasize= len(p.index)\n",
    "#print(\"{\")\n",
    "for i in range(model1.output()['C_RF']):\n",
    "    FNpolicy[i] = {}\n",
    "    \n",
    "    clusTemp = ndata1.loc[data1['label'] == i]\n",
    "    #clusTemp = FN.loc[FN['cluster'] == i]\n",
    "    clussize= len(clusTemp.index)\n",
    "    #print(i,\":{\",sep='',end=\"\")\n",
    "    #print(clusTemp.describe())\n",
    "    for col in ndata1.columns:\n",
    "        #actual data:  act[col].value_counts().to_dict()\n",
    "        # FN data: p[col].value_counts().to_dict()\n",
    "        # FP data: d[col].value_counts().to_dict()\n",
    "        datafreq =   p[col].value_counts().to_dict() # act[col].value_counts().to_dict()#\n",
    "#         print(datafreq)\n",
    "        #datafreq= pd.DataFrame.from_dict(datafreq, )\n",
    "        temp=clusTemp[col].value_counts().to_dict()\n",
    "#         print(temp)\n",
    "        for key, value in datafreq.items():\n",
    "            \n",
    "            \n",
    "            for key1, value1 in temp.items():\n",
    "#                 print(key, key1)\n",
    "                if key == key1:\n",
    "                    #print(key ,value,value1)\n",
    "                    x = value1/datasize\n",
    "                    y = value1/clussize\n",
    "                    #print((y-x))\n",
    "                    #if key in centroids[i]:\n",
    "                    if (y-x) >= 0.549:\n",
    "                        if col not in FNpolicy[i]:\n",
    "                            FNpolicy[i][col] = key\n",
    "                    for col2 in ndata1.columns:\n",
    "                                if col !=col2:\n",
    "                                    clusTemp = ndata1.loc[data1['label'] == i]\n",
    "#                                     clus = clusTemp.loc[clusTemp[col] == clusTemp[col2]]\n",
    "                                    clus = clusTemp.loc[clusTemp[col].astype(str) == clusTemp[col2].astype(str)]\n",
    "                                    if len(clus) >= len(clusTemp)/2:\n",
    "                                        #print(\"'\",col,\"':'\",col2,\"',\",sep='',end=\"\")\n",
    "                                        if col not in FNpolicy[i] and col2 not in FNpolicy[i]: \n",
    "                                            FNpolicy[i][col] = col2\n",
    "                                        else:\n",
    "                                            if col in FNpolicy[i]: \n",
    "                                                FNpolicy[i][col] = col2\n",
    "                                            if col2 in FNpolicy[i] :\n",
    "                                                del FNpolicy[i][col2]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "print(FNpolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "913e57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{0: {'action': 'read', 'position': 'faculty', 'type': 'roster', 'crstaken': 'crs'}, 1: {'ischair': 'TRUE', 'action': 'read', 'type': 'transcript'}, 2: {'action': 'readmyscores', 'type': 'gradebook', 'crstaken': 'crs'}, 3: {'odepartment': 'admissions', 'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 4: {'action': 'checkstatus', 'position': 'student', 'type': 'application'}, 5: {'action': 'addscore', 'type': 'gradebook', 'crstaken': 'crstaught'}, 6: {'action': 'read', 'type': 'roster', 'udepartment': 'registrar'}, 7: {'action': 'readmyscores', 'type': 'gradebook', 'crstaken': 'crs'}, 8: {'action': 'readmyscores', 'type': 'gradebook', 'crstaken': 'crs'}, 9: {'action': 'read', 'position': 'faculty', 'type': 'application', 'udepartment': 'admissions'}}\n"
     ]
    }
   ],
   "source": [
    "# refine the extracted policy based on FN policy \n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "        intersection = (set(list1.values()).intersection(list2.values()))\n",
    "        #print(list(set(list1).intersection(list2)))\n",
    "        union = defaultdict(list)\n",
    "        for k, v in chain(list1.items(), list2.items()):\n",
    "        #if v not in intersection:\n",
    "            union[k].append(v)\n",
    "    #print(union)    \n",
    "    \n",
    "        intersectionl = len(intersection)\n",
    "        unionl = len(union)\n",
    "        score = float(intersectionl / unionl)\n",
    "        #print(len(policy[key]),len(FNpolicy[key2]))\n",
    "        if score >= 0.5:\n",
    "            if len(policy[key]) > len(FNpolicy[key2]) and len(FNpolicy[key2])>=2 :\n",
    "                #print(len(policy[key]),len(FNpolicy[key2]))\n",
    "                policy[key] = FNpolicy[key2]\n",
    "                print(key, \",\",key2,\" score =\", score,unionl,intersectionl)\n",
    "                print( (set(list1).intersection(list2)),\"\\n\" ,union)\n",
    "                #print(intersectionl)\n",
    "        \n",
    "        return float(intersectionl / unionl)\n",
    "        return float(intersectionl / unionl)\n",
    "    \n",
    "#rules = policy\n",
    "for key, value in policy.items():\n",
    "    \n",
    "    for key2, v  in FNpolicy.items():\n",
    "        #print(key, key2)\n",
    "        \n",
    "        #if key !=key2:\n",
    "            \n",
    "            #print(key, key2)\n",
    "            \"\"\"for z, j in value.items():\n",
    "                for y, i in v.items():\n",
    "                     if z == y:\"\"\"\n",
    "            #score = jaccard_similarity_score(value, v)\n",
    "            score = jaccard_similarity(value, v)\n",
    "                        #print(i,j)\n",
    "            \"\"\"if score > 0.6:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",k,\" score =\", score)\n",
    "    \"\"\"\n",
    "print(sum(len(v) for v in FNpolicy.values()))\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "443f01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ischair    crs odepartment       action position         type  \\\n",
      "0       FALSE  ee601          cs         read  faculty       roster   \n",
      "1       FALSE  cs101          ee         read  faculty       roster   \n",
      "2        TRUE  ee601          cs         read  advisor   transcript   \n",
      "3        TRUE  ee101          cs         read  advisor   transcript   \n",
      "4        TRUE  cs101   registrar         read    staff  application   \n",
      "...       ...    ...         ...          ...      ...          ...   \n",
      "15996      na  ee101          ee    setstatus    staff       roster   \n",
      "15997    TRUE  ee101   registrar        write  faculty    gradebook   \n",
      "15998    TRUE  ee101          cs         read  faculty    gradebook   \n",
      "15999    TRUE  ee101   registrar  changescore    staff   transcript   \n",
      "16000      na  ee101  admissions    setstatus    staff   transcript   \n",
      "\n",
      "      udepartment crstaught crstaken class lable  \n",
      "0       registrar     ee101    ee601     p     p  \n",
      "1              ce     ee601    cs101     p     p  \n",
      "2       registrar     ee101    cs602     p     p  \n",
      "3              ce     cs101    cs101     p     p  \n",
      "4      admissions     cs101    ee101     p     d  \n",
      "...           ...       ...      ...   ...   ...  \n",
      "15996          ee     cs101    cs601     d     d  \n",
      "15997   registrar     ee601    cs602     d     d  \n",
      "15998          ee     cs101    cs602     d     d  \n",
      "15999  admissions     cs602    ee101     d     d  \n",
      "16000          ee     cs602    ee601     d     d  \n",
      "\n",
      "[16001 rows x 11 columns]\n",
      "--- 2.4606170654296875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# run the extracted policy over the complete data  (FN)\n",
    "import time\n",
    "def dict_compare(d1, d2):\n",
    "    d1_keys = set(d1.keys())\n",
    "    d2_keys = set(d2.keys())\n",
    "\n",
    "    intersect_keys = d1_keys.intersection(d2_keys)\n",
    " \n",
    "    relation = []\n",
    "    added = d1_keys - d2_keys\n",
    "    removed = d2_keys - d1_keys\n",
    "  \n",
    "    same = set(o for o in intersect_keys if  d1[o] in d2[o] )\n",
    "   \n",
    "    if len(same) == len(intersect_keys):\n",
    "        return added, removed, same, relation\n",
    "    for key,  o in d2.items():\n",
    "        if type(o) == str:\n",
    "                \n",
    " \n",
    "            temp = set(i for i in intersect_keys if type(d2[i]) == str and d2[i] in d1_keys and d1[i] == d1[d2[i]] )\n",
    "                #print(temp)\n",
    "            if len(temp)>0:\n",
    "                    relation = temp\n",
    "        \n",
    "           \n",
    "    return added, removed, same, relation\n",
    "\n",
    "\n",
    "def ruleCheck (row):\n",
    "    lable = 'd'\n",
    "    drow = row.to_dict()\n",
    "    \n",
    "    for key,value in policy.items():\n",
    "        #print(key)\n",
    "        added, removed, same, relation = dict_compare(drow, value)\n",
    "        \n",
    "        if len(same)+len(relation) >= len(value) or len(same) == len(value):\n",
    "            #print(len(same)+len(relation), len(value))\n",
    "            lable = \"p\"\n",
    "#             row ['lable'] ='p'\n",
    "            return lable\n",
    "    \n",
    "    return lable\n",
    "start_time = time.time()\n",
    "\n",
    "act['lable'] = act.apply(ruleCheck, axis=1)\n",
    "print(act)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09961d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN= 1760 , FP= 68 , TP= 6240 , TN= 7933\n",
      "recall = 78.0 \n",
      "precession = 98.92200380469245 \n",
      "accuracy =  88.57571401787389 \n",
      "f-score =  87.22393066815768\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "log = act[(act['class'] == \"p\") & (act['lable'] == \"p\")]\n",
    "log2 = act[(act['class'] == \"d\") & (act['lable'] == \"d\")]\n",
    "FN = act[(act['class'] == \"p\") & (act['lable'] == \"d\")]\n",
    "FP = act[(act['class'] == \"d\") & (act['lable'] == \"p\")]\n",
    "\n",
    "p = act[act['class'] == \"p\"]\n",
    "d = act[act['class'] == \"d\"]\n",
    "#[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "#print(len(log),'\\n', log.head(10))\n",
    "#print(FN.describe(),FP.describe(),log2.describe(),d.describe())\n",
    "#log.describe()\n",
    "print(\"FN=\", len(FN), \", FP=\", len(FP), \", TP=\", len(log), \", TN=\", len(log2))\n",
    "recall = (len(log)/(len(log)+len(FN)))*100\n",
    "precesion = (len(log)/(len(log)+len(FP)))*100\n",
    "accu = ((len(log)+len(log2))/len(act))*100\n",
    "f = 2*((recall*precesion)/(recall+precesion))\n",
    "print(\"recall =\",recall, \"\\nprecession =\",precesion, \"\\naccuracy = \", accu,\"\\nf-score = \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff0f83dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ischair    crs odepartment       action position       type udepartment  \\\n",
      "0        na  cs602          cs  checkstatus    staff  gradebook   registrar   \n",
      "1        na  ee101  admissions         read    staff  gradebook   registrar   \n",
      "2        na  cs101          ce  checkstatus  student  gradebook   registrar   \n",
      "3      TRUE  cs602   registrar         read    staff  gradebook          cs   \n",
      "4     FALSE  cs601  admissions        write  student  gradebook   registrar   \n",
      "..      ...    ...         ...          ...      ...        ...         ...   \n",
      "116   FALSE  cs602          ee    setstatus  faculty  gradebook   registrar   \n",
      "117    TRUE  cs601  admissions    setstatus  advisor  gradebook   registrar   \n",
      "118      na  ee101          ce  changescore  faculty  gradebook   registrar   \n",
      "119    TRUE  cs602  admissions         read  faculty  gradebook          ce   \n",
      "120    TRUE  cs602          cs  checkstatus  faculty  gradebook   registrar   \n",
      "\n",
      "    crstaught crstaken                                             concat  \n",
      "0       ee101    ee101  nacs602cscheckstatusstaffgradebookregistraree1...  \n",
      "1       ee601    ee601  naee101admissionsreadstaffgradebookregistraree...  \n",
      "2       cs101    cs101  nacs101cecheckstatusstudentgradebookregistrarc...  \n",
      "3       cs602    cs602   TRUEcs602registrarreadstaffgradebookcscs602cs602  \n",
      "4       cs601    cs601  FALSEcs601admissionswritestudentgradebookregis...  \n",
      "..        ...      ...                                                ...  \n",
      "116     ee101    ee101  FALSEcs602eesetstatusfacultygradebookregistrar...  \n",
      "117     ee101    ee101  TRUEcs601admissionssetstatusadvisorgradebookre...  \n",
      "118     ee601    ee601  naee101cechangescorefacultygradebookregistrare...  \n",
      "119     cs101    cs602  TRUEcs602admissionsreadfacultygradebookcecs101...  \n",
      "120     cs602    cs602  TRUEcs602cscheckstatusfacultygradebookregistra...  \n",
      "\n",
      "[121 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "def concat_strings(row):\n",
    "    return ''.join(row)\n",
    "\n",
    "# 使用apply()方法和lambda表达式对每一行的数据进行处理\n",
    "data2 =  FP.drop(columns=['class','lable']).reset_index() #FN.drop(columns=['class','lable']) #FP.drop(columns=['class','lable'])#ReFN.drop(columns=['class','lable','lable1','lable2']) #ReFN.drop(columns=['class','lable','lable1']).reset_index() #FN.drop(columns=['class','lable']) #df\n",
    "data2 = data2.drop(columns=['index'])\n",
    "data2['concat'] = data2.apply(lambda row: concat_strings(row), axis=1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eafbd921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the parameter 'n'\n",
      "Parameter 'n' is set to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Segmentation (Splitting based on window size): 100%|████████████████████| 121/121 [00:00<00:00, 17274.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding + x/y train\n",
      "Fit RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\s's'y\\AppData\\Local\\Temp\\ipykernel_29568\\3262524878.py:208: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  self.seg_mat.loc[:,'Class']   = le.fit_transform(self.seg_mat.loc[:,'Class']) # Convert Y to numbers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame of terminal nodes\n",
      "Determining the cosine Distance\n",
      "Applying Ward Linkage\n",
      "Cutting The Tree\n"
     ]
    }
   ],
   "source": [
    "# FP\n",
    "model2 = nTreeClus(list(data2.concat), n=None, ntree=10, method=\"RF\", verbose=1, C=10)\n",
    "model2.nTreeClus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023e6a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ischair    crs odepartment       action position       type udepartment  \\\n",
      "0        na  cs602          cs  checkstatus    staff  gradebook   registrar   \n",
      "1        na  ee101  admissions         read    staff  gradebook   registrar   \n",
      "2        na  cs101          ce  checkstatus  student  gradebook   registrar   \n",
      "3      TRUE  cs602   registrar         read    staff  gradebook          cs   \n",
      "4     FALSE  cs601  admissions        write  student  gradebook   registrar   \n",
      "..      ...    ...         ...          ...      ...        ...         ...   \n",
      "116   FALSE  cs602          ee    setstatus  faculty  gradebook   registrar   \n",
      "117    TRUE  cs601  admissions    setstatus  advisor  gradebook   registrar   \n",
      "118      na  ee101          ce  changescore  faculty  gradebook   registrar   \n",
      "119    TRUE  cs602  admissions         read  faculty  gradebook          ce   \n",
      "120    TRUE  cs602          cs  checkstatus  faculty  gradebook   registrar   \n",
      "\n",
      "    crstaught crstaken                                             concat  \\\n",
      "0       ee101    ee101  nacs602cscheckstatusstaffgradebookregistraree1...   \n",
      "1       ee601    ee601  naee101admissionsreadstaffgradebookregistraree...   \n",
      "2       cs101    cs101  nacs101cecheckstatusstudentgradebookregistrarc...   \n",
      "3       cs602    cs602   TRUEcs602registrarreadstaffgradebookcscs602cs602   \n",
      "4       cs601    cs601  FALSEcs601admissionswritestudentgradebookregis...   \n",
      "..        ...      ...                                                ...   \n",
      "116     ee101    ee101  FALSEcs602eesetstatusfacultygradebookregistrar...   \n",
      "117     ee101    ee101  TRUEcs601admissionssetstatusadvisorgradebookre...   \n",
      "118     ee601    ee601  naee101cechangescorefacultygradebookregistrare...   \n",
      "119     cs101    cs602  TRUEcs602admissionsreadfacultygradebookcecs101...   \n",
      "120     cs602    cs602  TRUEcs602cscheckstatusfacultygradebookregistra...   \n",
      "\n",
      "     label  \n",
      "0        0  \n",
      "1        1  \n",
      "2        2  \n",
      "3        3  \n",
      "4        4  \n",
      "..     ...  \n",
      "116      0  \n",
      "117      0  \n",
      "118      6  \n",
      "119      1  \n",
      "120      5  \n",
      "\n",
      "[121 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data2['label'] = model2.output()['labels_RF']\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1b992c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ischair</th>\n",
       "      <th>crs</th>\n",
       "      <th>odepartment</th>\n",
       "      <th>action</th>\n",
       "      <th>position</th>\n",
       "      <th>type</th>\n",
       "      <th>udepartment</th>\n",
       "      <th>crstaught</th>\n",
       "      <th>crstaken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>na</td>\n",
       "      <td>cs602</td>\n",
       "      <td>cs</td>\n",
       "      <td>checkstatus</td>\n",
       "      <td>staff</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee101</td>\n",
       "      <td>ee101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>ee101</td>\n",
       "      <td>admissions</td>\n",
       "      <td>read</td>\n",
       "      <td>staff</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee601</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>cs101</td>\n",
       "      <td>ce</td>\n",
       "      <td>checkstatus</td>\n",
       "      <td>student</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>cs101</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>cs602</td>\n",
       "      <td>registrar</td>\n",
       "      <td>read</td>\n",
       "      <td>staff</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs602</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>cs601</td>\n",
       "      <td>admissions</td>\n",
       "      <td>write</td>\n",
       "      <td>student</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>cs601</td>\n",
       "      <td>cs601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>cs602</td>\n",
       "      <td>ee</td>\n",
       "      <td>setstatus</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee101</td>\n",
       "      <td>ee101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>cs601</td>\n",
       "      <td>admissions</td>\n",
       "      <td>setstatus</td>\n",
       "      <td>advisor</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee101</td>\n",
       "      <td>ee101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>na</td>\n",
       "      <td>ee101</td>\n",
       "      <td>ce</td>\n",
       "      <td>changescore</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>ee601</td>\n",
       "      <td>ee601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>cs602</td>\n",
       "      <td>admissions</td>\n",
       "      <td>read</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>ce</td>\n",
       "      <td>cs101</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>cs602</td>\n",
       "      <td>cs</td>\n",
       "      <td>checkstatus</td>\n",
       "      <td>faculty</td>\n",
       "      <td>gradebook</td>\n",
       "      <td>registrar</td>\n",
       "      <td>cs602</td>\n",
       "      <td>cs602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ischair    crs odepartment       action position       type udepartment  \\\n",
       "0        na  cs602          cs  checkstatus    staff  gradebook   registrar   \n",
       "1        na  ee101  admissions         read    staff  gradebook   registrar   \n",
       "2        na  cs101          ce  checkstatus  student  gradebook   registrar   \n",
       "3      TRUE  cs602   registrar         read    staff  gradebook          cs   \n",
       "4     FALSE  cs601  admissions        write  student  gradebook   registrar   \n",
       "..      ...    ...         ...          ...      ...        ...         ...   \n",
       "116   FALSE  cs602          ee    setstatus  faculty  gradebook   registrar   \n",
       "117    TRUE  cs601  admissions    setstatus  advisor  gradebook   registrar   \n",
       "118      na  ee101          ce  changescore  faculty  gradebook   registrar   \n",
       "119    TRUE  cs602  admissions         read  faculty  gradebook          ce   \n",
       "120    TRUE  cs602          cs  checkstatus  faculty  gradebook   registrar   \n",
       "\n",
       "    crstaught crstaken  \n",
       "0       ee101    ee101  \n",
       "1       ee601    ee601  \n",
       "2       cs101    cs101  \n",
       "3       cs602    cs602  \n",
       "4       cs601    cs601  \n",
       "..        ...      ...  \n",
       "116     ee101    ee101  \n",
       "117     ee101    ee101  \n",
       "118     ee601    ee601  \n",
       "119     cs101    cs602  \n",
       "120     cs602    cs602  \n",
       "\n",
       "[121 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata2=data2.drop(columns='concat')\n",
    "ndata2=ndata2.drop(columns='label')\n",
    "ndata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced0103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.073983669281006 seconds ---\n",
      "{0: {'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 1: {'action': 'read', 'type': 'gradebook', 'udepartment': 'admissions', 'crstaken': 'crs'}, 2: {'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 3: {'ischair': 'TRUE', 'odepartment': 'registrar', 'action': 'read', 'position': 'staff', 'type': 'gradebook', 'crstaken': 'crstaught'}, 4: {'odepartment': 'admissions', 'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 5: {'type': 'gradebook', 'udepartment': 'registrar', 'crstaken': 'crstaught'}, 6: {'ischair': 'na', 'action': 'changescore', 'type': 'gradebook', 'udepartment': 'odepartment', 'crstaken': 'crstaught'}, 7: {'action': 'read', 'type': 'gradebook', 'crstaken': 'crs'}, 8: {'ischair': 'FALSE', 'action': 'read', 'position': 'advisor', 'type': 'gradebook', 'udepartment': 'cs', 'crstaught': 'ee101', 'crstaken': 'crs'}, 9: {'ischair': 'FALSE', 'odepartment': 'registrar', 'action': 'read', 'position': 'student', 'type': 'gradebook', 'crstaught': 'ee101', 'crstaken': 'crs'}}\n"
     ]
    }
   ],
   "source": [
    "# Calculating FP Attributes Effectevness in each cluster\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "#print(datafreq)\n",
    "clusTemp = pd.DataFrame()\n",
    "\n",
    "FPpolicy ={}\n",
    "###change FN: p, FP: d or act\n",
    "datasize= len(d.index)\n",
    "#print(\"{\")\n",
    "for i in range(model2.output()['C_RF']):\n",
    "    FPpolicy[i] = {}\n",
    "    \n",
    "    clusTemp = ndata2.loc[data2['label'] == i]\n",
    "    #clusTemp = FN.loc[FN['cluster'] == i]\n",
    "    clussize= len(clusTemp.index)\n",
    "    #print(i,\":{\",sep='',end=\"\")\n",
    "    #print(clusTemp.describe())\n",
    "    for col in ndata2.columns:\n",
    "        #actual data:  act[col].value_counts().to_dict()\n",
    "        # FN data: p[col].value_counts().to_dict()\n",
    "        # FP data: d[col].value_counts().to_dict()\n",
    "        datafreq =   d[col].value_counts().to_dict() # act[col].value_counts().to_dict()#\n",
    "#         print(datafreq)\n",
    "        #datafreq= pd.DataFrame.from_dict(datafreq, )\n",
    "        temp=clusTemp[col].value_counts().to_dict()\n",
    "#         print(temp)\n",
    "        for key, value in datafreq.items():\n",
    "            \n",
    "            \n",
    "            for key1, value1 in temp.items():\n",
    "#                 print(key, key1)\n",
    "                if key == key1:\n",
    "                    #print(key ,value,value1)\n",
    "                    x = value1/datasize\n",
    "                    y = value1/clussize\n",
    "                    #print((y-x))\n",
    "                    #if key in centroids[i]:\n",
    "                    if (y-x) >= 0.549:\n",
    "                        if col not in FPpolicy[i]:\n",
    "                            FPpolicy[i][col] = key\n",
    "                    for col2 in ndata2.columns:\n",
    "                                if col !=col2:\n",
    "                                    clusTemp = ndata2.loc[data2['label'] == i]\n",
    "#                                     clus = clusTemp.loc[clusTemp[col] == clusTemp[col2]]\n",
    "                                    clus = clusTemp.loc[clusTemp[col].astype(str) == clusTemp[col2].astype(str)]\n",
    "                                    if len(clus) >= len(clusTemp)/2:\n",
    "                                        #print(\"'\",col,\"':'\",col2,\"',\",sep='',end=\"\")\n",
    "                                        if col not in FPpolicy[i] and col2 not in FPpolicy[i]: \n",
    "                                            FPpolicy[i][col] = col2\n",
    "                                        else:\n",
    "                                            if col in FPpolicy[i]: \n",
    "                                                FPpolicy[i][col] = col2\n",
    "                                            if col2 in FPpolicy[i] :\n",
    "                                                del FPpolicy[i][col2]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "print(FPpolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4326fcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 , 1  score = 0.5 4 2\n",
      "{'type', 'udepartment', 'action'} \n",
      " defaultdict(<class 'list'>, {'action': ['read', 'read'], 'type': ['application', 'gradebook'], 'udepartment': ['admissions', 'admissions'], 'crstaken': ['crs']})\n",
      "3 , 4  score = 0.75 4 3\n",
      "{'type', 'crstaken', 'udepartment'} \n",
      " defaultdict(<class 'list'>, {'type': ['gradebook', 'gradebook'], 'udepartment': ['registrar', 'registrar'], 'crstaken': ['crstaught', 'crstaught'], 'odepartment': ['admissions']})\n",
      "8 , 1  score = 0.5 4 2\n",
      "{'type', 'crstaken', 'action'} \n",
      " defaultdict(<class 'list'>, {'action': ['readmyscores', 'read'], 'type': ['gradebook', 'gradebook'], 'crstaken': ['crs', 'crs'], 'udepartment': ['admissions']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refine the extracted policy based on FP policy \n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "        intersection = (set(list1.values()).intersection(list2.values()))\n",
    "        #print(list(set(list1).intersection(list2)))\n",
    "        union = defaultdict(list)\n",
    "        for k, v in chain(list1.items(), list2.items()):\n",
    "        #if v not in intersection:\n",
    "            union[k].append(v)\n",
    "    #print(union)    \n",
    "    \n",
    "        intersectionl = len(intersection)\n",
    "        unionl = len(union)\n",
    "        score = float(intersectionl / unionl)\n",
    "        #print(len(policy[key]),len(FNpolicy[key2]))\n",
    "        if score >= 0.5:\n",
    "            if len(policy[key]) < len(FPpolicy[key2])  :\n",
    "                #print(len(policy[key]),len(FPpolicy[key2]))\n",
    "                \n",
    "                policy[key] = FPpolicy[key2]\n",
    "                print(key, \",\",key2,\" score =\", score,unionl,intersectionl)\n",
    "                print( (set(list1).intersection(list2)),\"\\n\" ,union)\n",
    "                #print(intersectionl)\n",
    "        \n",
    "        return float(intersectionl / unionl)\n",
    "        return float(intersectionl / unionl)\n",
    "    \n",
    "#rules = policy\n",
    "for key, value in policy.items():\n",
    "    \n",
    "    for key2, v  in FPpolicy.items():\n",
    "        #print(key, key2)\n",
    "        \n",
    "        #if key !=key2:\n",
    "            \n",
    "            #print(key, key2)\n",
    "            \"\"\"for z, j in value.items():\n",
    "                for y, i in v.items():\n",
    "                     if z == y:\"\"\"\n",
    "            #score = jaccard_similarity_score(value, v)\n",
    "            score = jaccard_similarity(value, v)\n",
    "                        #print(i,j)\n",
    "            \"\"\"if score > 0.6:\n",
    "                #print(i,j)\n",
    "                print(key, \",\",k,\" score =\", score)\n",
    "    \"\"\"\n",
    "sum(len(v) for v in policy.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee5f85ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ischair    crs odepartment       action position         type  \\\n",
      "0       FALSE  ee601          cs         read  faculty       roster   \n",
      "1       FALSE  cs101          ee         read  faculty       roster   \n",
      "2        TRUE  ee601          cs         read  advisor   transcript   \n",
      "3        TRUE  ee101          cs         read  advisor   transcript   \n",
      "4        TRUE  cs101   registrar         read    staff  application   \n",
      "...       ...    ...         ...          ...      ...          ...   \n",
      "15996      na  ee101          ee    setstatus    staff       roster   \n",
      "15997    TRUE  ee101   registrar        write  faculty    gradebook   \n",
      "15998    TRUE  ee101          cs         read  faculty    gradebook   \n",
      "15999    TRUE  ee101   registrar  changescore    staff   transcript   \n",
      "16000      na  ee101  admissions    setstatus    staff   transcript   \n",
      "\n",
      "      udepartment crstaught crstaken class lable  \n",
      "0       registrar     ee101    ee601     p     p  \n",
      "1              ce     ee601    cs101     p     p  \n",
      "2       registrar     ee101    cs602     p     p  \n",
      "3              ce     cs101    cs101     p     p  \n",
      "4      admissions     cs101    ee101     p     d  \n",
      "...           ...       ...      ...   ...   ...  \n",
      "15996          ee     cs101    cs601     d     d  \n",
      "15997   registrar     ee601    cs602     d     d  \n",
      "15998          ee     cs101    cs602     d     d  \n",
      "15999  admissions     cs602    ee101     d     d  \n",
      "16000          ee     cs602    ee601     d     d  \n",
      "\n",
      "[16001 rows x 11 columns]\n",
      "--- 2.4116225242614746 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# run the extracted policy over the complete data  (FP)\n",
    "import time\n",
    "def dict_compare(d1, d2):\n",
    "    d1_keys = set(d1.keys())\n",
    "    d2_keys = set(d2.keys())\n",
    "\n",
    "    intersect_keys = d1_keys.intersection(d2_keys)\n",
    " \n",
    "    relation = []\n",
    "    added = d1_keys - d2_keys\n",
    "    removed = d2_keys - d1_keys\n",
    "  \n",
    "    same = set(o for o in intersect_keys if  d1[o] in d2[o] )\n",
    "   \n",
    "    if len(same) == len(intersect_keys):\n",
    "        return added, removed, same, relation\n",
    "    for key,  o in d2.items():\n",
    "        if type(o) == str:\n",
    "                \n",
    " \n",
    "            temp = set(i for i in intersect_keys if type(d2[i]) == str and d2[i] in d1_keys and d1[i] == d1[d2[i]] )\n",
    "                #print(temp)\n",
    "            if len(temp)>0:\n",
    "                    relation = temp\n",
    "        \n",
    "           \n",
    "    return added, removed, same, relation\n",
    "\n",
    "\n",
    "def ruleCheck (row):\n",
    "    lable = 'd'\n",
    "    drow = row.to_dict()\n",
    "    \n",
    "    for key,value in policy.items():\n",
    "        #print(key)\n",
    "        added, removed, same, relation = dict_compare(drow, value)\n",
    "        \n",
    "        if len(same)+len(relation) >= len(value) or len(same) == len(value):\n",
    "            #print(len(same)+len(relation), len(value))\n",
    "            lable = \"p\"\n",
    "#             row ['lable'] ='p'\n",
    "            return lable\n",
    "    \n",
    "    return lable\n",
    "start_time = time.time()\n",
    "\n",
    "act['lable'] = act.apply(ruleCheck, axis=1)\n",
    "print(act)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "981f8929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN= 1991 , FP= 25 , TP= 6009 , TN= 7976\n",
      "recall = 75.11250000000001 \n",
      "precession = 99.58568114020551 \n",
      "accuracy =  87.40078745078432 \n",
      "f-score =  85.63488670371954\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "log = act[(act['class'] == \"p\") & (act['lable'] == \"p\")]\n",
    "log2 = act[(act['class'] == \"d\") & (act['lable'] == \"d\")]\n",
    "FN = act[(act['class'] == \"p\") & (act['lable'] == \"d\")]\n",
    "FP = act[(act['class'] == \"d\") & (act['lable'] == \"p\")]\n",
    "\n",
    "p = act[act['class'] == \"p\"]\n",
    "d = act[act['class'] == \"d\"]\n",
    "#[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "#print(len(log),'\\n', log.head(10))\n",
    "#print(FN.describe(),FP.describe(),log2.describe(),d.describe())\n",
    "#log.describe()\n",
    "print(\"FN=\", len(FN), \", FP=\", len(FP), \", TP=\", len(log), \", TN=\", len(log2))\n",
    "recall = (len(log)/(len(log)+len(FN)))*100\n",
    "precesion = (len(log)/(len(log)+len(FP)))*100\n",
    "accu = ((len(log)+len(log2))/len(act))*100\n",
    "f = 2*((recall*precesion)/(recall+precesion))\n",
    "print(\"recall =\",recall, \"\\nprecession =\",precesion, \"\\naccuracy = \", accu,\"\\nf-score = \", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testcluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
